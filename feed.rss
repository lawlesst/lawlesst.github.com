<?xml version="1.0" encoding="iso-8859-1"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Ted Lawless</title><link>http://lawlesst.github.com</link><description>Notes on projects.</description><lastBuildDate>Wed, 02 Jan 2013 11:45:04 GMT</lastBuildDate><generator>PyRSS2Gen-1.0.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Free text citations to library content</title><link>http://lawlesst.github.com/notebook/citation-finder.html</link><content:encoded><![CDATA[<p>On October 11, <a href="http://crossref.org/">CrossRef</a> <a href="http://labs.crossref.org/site/crossref_metadata_search.html">announced</a> a new metadata search service and <a href="http://search.labs.crossref.org/help/api">API</a>.  Jonathan Rochkind has a nice <a href="http://bibwild.wordpress.com/2012/10/11/new-crossref-metadata-search-with-api/">writeup</a> on the possibilities of integrating such a service with library software.  Jonathan writes the following in reference to the "links" feature which will take an unstructured citation and attempt to resolve it to a DOI: </p>
<blockquote class="modern">
    Looks like they also have an API for submitting a free-form citation, and getting back matches with DOI!  Its sort of a holy grail for me to provide a service where users can paste in a free-form citation, and get to our access/delivery options.
</blockquote>

<p>I've been doing a lot of work with <a href="./delivery.html">delivery</a> services lately and also see the value in being able to match raw text citations to actual content the library has licensed.  So I took Jonathan's statement as a bit of a challenge and an opportunity to explore the CrossRef API.  </p>
<h4 id="demo">Demo</h4>
<p>I put together a <a href="http://sleepy-island-6218.herokuapp.com/">demo application</a> that takes input from users, sends it to the CrossRef service, and, if a DOI is found, sends that DOI off to the <a href="http://www.serialssolutions.com/en/services/360-link">360Link</a> link resolver API to find a full text link in a library.  The screencast below shows two examples. </p>
<iframe src="http://www.screenr.com/embed/itV8" width="650" height="396" frameborder="0"></iframe>

<p>The code for the demo is <a href="https://github.com/lawlesst/citation-finder">available on Github</a>.  The server side code is minimal and built with <a href="http://flask.pocoo.org/">Flask</a>, the Python microframework for building web applications.  On the client side, jQuery and jQuery templates pull in the data and render it to the user.  </p>
<h4 id="recap-future-directions">Recap &amp; future directions</h4>
<p>The user interface and interaction could certainly stand for some improvement.  The citations that are resolvable are limited to what's in CrossRef's database, see their list of <a href="http://labs.crossref.org/quick_and_dirty_api_guides/resolving_citations.html">disclaimers</a>.  But - this work indicates building a service like this for library users is feasible and will be increasingly more valuable as services like these develop.  </p>
<p>CrossRef apparently <a href="http://labs.crossref.org/quick_and_dirty_api_guides/resolving_citations.html">doesn't parse</a> the free text into a formatted citation but constructs a query based on the free text against their database.  For further development, it would be worthwhile to try a similar approach with the <a href="http://api.summon.serialssolutions.com/">Summon API</a> and see if it could be possible to build a similar service on top of that data, since it contains a larger set of publications and articles.  </p>
<h4 id="examples">Examples</h4>
<p>If you are short on citations to try, here are a few I pulled from a <a href="http://repository.library.brown.edu:8080/fedora/objects/bdr:160/datastreams/PDF/content">dissertation</a>.  The third citation is to a working paper and doesn't resolve to a DOI via CrossRef so the interface offers a link to a search in Google Scholar, which does return a <a href="http://neeo.univ-tlse1.fr/294/1/collard_dellas.pdf">PDF to the paper</a>.  </p>
<pre><code>Christiano, L. J., M. Eichenbaum, and C. L. Evans (2005): Nominal Rigidities and the Dynamic Eects of a Shock to Monetary Policy, Journal of Political Economy, 113(1), 145.

Clarida, R., J. Gali, and M. Gertler (1999): The Science of Monetary Policy: A New Keynesian Perspective, Journal of Economic Literature, 37(4), 16611707.

Collard, F., and H. Dellas (2004): The new Keynesian model with imperfect information and learning, Working Paper, University of Toulouse.
</code></pre>
<p>Another feature of the demo app to note is that you can append a library's Serials Solutions code to the URL and the demo will search holdings for that library.  For example, this link will search the <a href="http://sleepy-island-6218.herokuapp.com/lg5jh7pa3n/">University of Victoria</a> holdings.  John Durno of Victoria has an <a href="http://journal.code4lib.org/articles/7308">article</a> in the most recent Code4Lib journal on some of their work with the 360Link API and delivery services.    </p>]]></content:encoded><description></description><guid>http://lawlesst.github.com/notebook/citation-finder.html</guid><pubDate>Wed, 17 Oct 2012 00:00:00 GMT</pubDate></item><item><title>Focusing on Delivery</title><link>http://lawlesst.github.com/notebook/delivery.html</link><content:encoded><![CDATA[<p>A <a href="https://twitter.com/hochstenbach/status/251929102024597504">Twitter exchange</a> between <a href="https://twitter.com/intent/user?screen_name=hochstenbach">Patrick Hochstenbach</a> and <a href="https://twitter.com/rcallewaert">Rosemie Callewaert
</a> voiced the opinion that library "discovery systems should focus more on delivery".  I agree - completely - and would like to describe some of the work I've been a part of recently that focuses on delivery of library content. </p>
<p>At the Brown University Library, we have recently taken steps to improve the delivery of journal articles to library users.  We call the project easyArticle<sup id="fnref:code"><a class="footnote-ref" href="#fn:code" rel="footnote">1</a></sup>.  When a user clicks on the 'Findit @Brown' link in various databases (including Google Scholar) or clicks the access link in our <a href="http://www.serialssolutions.com/en/services/summon/">Summon</a> <a href="http://library.brown.edu/find/Summon/Search?lookfor=learning+to+use+word+processors&amp;type=AllFields&amp;filter[]=holdingsOnly%3A%22false%22&amp;view=list">front-end</a>, she is routed through this system.  </p>
<p>In its most basic form, easyArticle is a front-end to the 360Link link resolver from Serials Solutions.  However it adds a fair amount of functionality beyond the typical link resolver.  The biggest addition to date is the automated submission of Interlibrary Loan and document delivery requests.  This along with the <a href="http://library.brown.edu/its/software/easyborrow/">easyBorrow</a> project at Brown, which focuses on obtaining copies of books, consist of our "delivery" services.  </p>
<p>This screencast demonstrates a search in Google Scholar that leads to the user requesting an article via Interlibrary Loan through this application<sup id="fnref:code"><a class="footnote-ref" href="#fn:code" rel="footnote">1</a></sup>.  Below the screencast is a list of user scenarios and how the easyArticle system is delivery the content to the user.  <br />
<div style="width: 700px; margin: 1em; margin-left:auto; margin-right:auto; padding:1em;">
<iframe src="http://www.screenr.com/embed/B1a8" width="650" height="396" frameborder="0"></iframe>
</div></p>
<h3 id="user-scenarios-for-our-easyarticle-link-resolver-or-article-delivery-platform">User scenarios for our easyArticle link resolver, or article delivery platform.</h3>
<h4 id="library-has-a-license-to-an-electronic-version-of-the-article-or-knows-of-an-open-access-electronic-copy-of-the-article">Library has a license to an electronic version of the article or knows of an open access electronic copy of the article.</h4>
<p>The user is <a href="http://library.brown.edu/easyarticle/get/eaB/">presented with link</a> to the electronic version, much like most link resolvers.  Although this page is served by a locally developed web application so we have complete control over its appearance and content.  </p>
<h4 id="library-holds-the-print-version-of-the-article">Library holds the print version of the article.</h4>
<p>Students are presented with the location in the stacks of the item.  <a href="http://library.brown.edu/easyarticle/get/eaC/">Example</a>. This also uses a locally developed web service, called the <a href="https://bitbucket.org/bul/book-locator">book locator</a>, to give the user the exact floor and aisle location of the item.</p>
<p>Faculty can click a 'request' link that will create a document delivery request in Illiad.  Library staff will then retrieve the item from the stacks, scan it, and it will be delivered via the document delivery software. </p>
<h4 id="library-does-not-license-an-electronic-copy-of-the-article-and-does-not-hold-a-print-copy-of-the-article">Library does not license an electronic copy of the article and does not hold a print copy of the article.</h4>
<p>Users are offered a request link.  If the user is not authenticated, the user is prompted to login via the campus Shibboleth system.  After clicking a confirmation button, the request is submitted to Illiad.  </p>
<p>The library is a member of the <a href="http://rapid2.library.colostate.edu/Public/AboutRapid">RapidILL</a> resource sharing network.  Requests that are available via this network are delivered to the users with 24 hours (Monday through Friday) of receipt.  If you aren't familiar with Rapid, there is more information in this <a href="http://www.ilds2011.org/presentations/Delaney_RapidILL_ILDS2011_2011-09-19.pdf">presentation</a>.  It's a great collaborative effort.  </p>
<p>Requests not available via Rapid are then processed through normal ILL procedures and documents are delivered directly via the Illiad software.  </p>
<h4 id="something-goes-wrong">Something goes wrong.</h4>
<p>Unfortunately not all OpenURLs contain enough metadata or the holdings information in the knowledgebase isn't quite right and users can't get the article they are looking for.  In these instances, we offer users a simple problem report form that contains a link to the citation and their IP address that will help staff track down the problem.  This has led to speedier resolution of problems and a more centralized place to track problems and identify which platforms aren't working well with OpenURL.  </p>
<div class="footnote">
<hr />
<ol>
<li id="fn:code">
<p>Many of the components of this application are <a href="https://github.com/lawlesst">available on Github</a> as separate Python modules.  I also <a href="http://lawlesst.github.com/notebook/heroku360link.html">wrote previously</a> about building a demo application on Heroku that provides the basic functionality of this application. &#160;<a class="footnote-backref" href="#fnref:code" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>]]></content:encoded><description></description><guid>http://lawlesst.github.com/notebook/delivery.html</guid><pubDate>Sun, 30 Sep 2012 00:00:00 GMT</pubDate></item><item><title>Django, Heroku, and the 360Link API</title><link>http://lawlesst.github.com/notebook/heroku360link.html</link><content:encoded><![CDATA[<blockquote>
<p>This post describes a <a href="http://damp-tor-3124.herokuapp.com/">demo application</a> that serves as a front-end to the <a href="http://www.serialssolutions.com/en/services/360-link">360Link OpenURL resolver</a>
from Serials Solutions.  The code is available on <a href="https://github.com/lawlesst/heroku-360link">Github</a> and the application is running on Heroku.    </p>
</blockquote>
<p>A recent <a href="http://serials.infomotions.com/code4lib/archive/2012/201209/2516.html">thread</a> on the Code4Lib mailing list discussed technical details of the <a href="http://www.serialssolutions.com/en/services/360-link">360Link </a> OpenURL resolver.  The technical details are interesting because the OpenURL resolver is often the last handoff from the library systems to the location on the web where users can actually get what they are looking for.  If something goes wrong, it's a frustating experience for everyone involved. </p>
<p>Over the last year, my colleagues and I at Brown University Library have developed a new front-end to 360Link using the <a href="http://www.serialssolutions.com/en/services/360-search/xml-api">360Link API</a>.  It's been serving OpenURL requests since February and, as of August, has completely replaced our use of the default 360Link interface.  The main objective of this project was to streamline the delivery of content found in various databases.  </p>
<p>Since 360Link is rather popular in academic libraries and other libaries might be interested in implementing their own front-end, I decided to put together a demo <a href="https://www.djangoproject.com/">Django</a> application that uses the API to create a basic link resolver.    </p>
<p>Here are a few sample links.  You can also paste an OpenURL into the form on the <a href="http://damp-tor-3124.herokuapp.com/">index page</a></p>
<ul>
<li><a href="http://damp-tor-3124.herokuapp.com/?doi=doi/10.2202/1542-0485.1188">Sample article lookup</a></li>
<li><a href="http://damp-tor-3124.herokuapp.com/?pmid=22953657">Pubmed lookup</a></li>
<li><a href="http://damp-tor-3124.herokuapp.com/?pmid=22953657&amp;output=json">JSON(P) responses</a> via content negotiation or adding output=json to the OpenURL. </li>
<li><a href="http://damp-tor-3124.herokuapp.com/dl2af5jf3e/?pmid=22953657">Another sample response</a> but a customer code has been added to the url to switch to another library's API.  </li>
</ul>
<p>You can easily switch libraries by adding another library's Serials Solutions customer code to the URL - e.g Brown's default 360Link interface is at http://rl3tp7zf5x.search.serialssolutions.com/ so the customer code is "rl3tp7z5x".  While testing this, I noticed that some library's API requires authentictation but most seem to be open and testable.  </p>
<p>To run some real requests through this app, you could login to <a href="http://www.mendeley.com/">Mendeley</a> and set it as your resolver in the Find this paper at dropdown menu.   </p>
<p>The app is running on Heroku and the code is on <a href="https://github.com/lawlesst/heroku-360link">Github</a>.  As far as I know, any library that subscribes to 360Link also has access to the API, so you could checkout this code, make a few tweaks, and have it running for your library pretty quickly.  If you take a look, you'll notice that it's a couple of URL routes and a few dozen lines of controller (view in Django) code.  So it takes less work to get started with the API than you might suspect.  </p>
<p>For more details about working with the API, Daniel Talsky did a nice job of <a href="http://journal.code4lib.org/articles/108">explaining the API</a> in Issue 4, 2008  of the Code4Lib Journal.    </p>
<p>At Brown we have seen some performance issues with the API, particularly with Pubmed ID lookups, but these issues are also present in the default interface too.  Overall it's been quite rewarding to have control over the link resolver interface and to dive in and add new features that make it easier for patrons to get to library content.  </p>]]></content:encoded><description></description><guid>http://lawlesst.github.com/notebook/heroku360link.html</guid><pubDate>Tue, 11 Sep 2012 00:00:00 GMT</pubDate></item><item><title> A Python module for placing requests in ILLiad </title><link>http://lawlesst.github.com/notebook/illiad-api.html</link><content:encoded><![CDATA[<blockquote>
<p>This post describes a <a href="https://github.com/lawlesst/illiad-api">Python module</a> for creating requests in <a href="http://www.atlas-sys.com/illiad/">ILLiad</a>, the interlibrary loan software used in libraries.  </p>
</blockquote>
<p>Many libraries use <a href="http://www.atlas-sys.com/illiad/">ILLiad</a> as the software system for document delivery and interlibrary loan services.  As a developer working with this system, you might find a need to create ILLiad requests programmatically from another system.  This other system could be your library catalog or OpenURL resolver or just a standalone script that processes batches of requests.  However ILLiad doesn't support an API for creating requests.  In response to this, at <a href="http://library.brown.edu">Brown University Libraries</a> we have developed a Python module that serves as a programming interface to ILLiad.  The code for the module is <a href="https://github.com/lawlesst/illiad-api">available on Github</a> for downloading, forking, and inspection.  It relies on two Python libraries, <a href="http://docs.python-requests.org/en/latest/">requests</a> for creating HTTP requests and <a href="http://packages.python.org/pyquery/">pyquery</a>, which provides a nice syntax for parsing HTML documents.</p>
<h3 id="request-workflow">Request workflow</h3>
<p>This is the basic worfklow for the module:</p>
<ul>
<li>authenticate or verify the user in your external system.  </li>
<li>establish an ILLiad session on behalf of the user.  Retain the returned session cookie for further requests.</li>
<li>pass an OpenURL to ILLiad for the item the user is requesting.</li>
<li>parse the response, which is an HTML form with populated values from the OpenURL.  If you were doing this manually from the ILLiad user interface, this would be the pre-populated form that the user sees and either enhances with more information or clicks submit to process.  </li>
<li>post the values returned by the step above to the ILLiad server. </li>
<li>parse the response.  This response will contain either the transaction number for the request or an error message describing what when wrong.  </li>
<li>log the user out.    </li>
</ul>
<h3 id="example-in-code">Example in code</h3>
<p><div style="width: 800px; margin: 1em; padding:1em;">
<script src="https://gist.github.com/4422229.js"></script>
</div></p>
<h3 id="how-does-the-module-work">How does the module work?</h3>
<p>ILLiad ships with a set of web forms that will respond to <a href="http://en.wikipedia.org/wiki/OpenURL">OpenURL</a> requests and pre-populate forms with the appropriate data.  The module will open ILLiad web pages on a user's behalf, parse the responses, and post values to the ILLiad server.</p>
<p>The module does rely on screen scraping the HTML returned by the ILLiad application but experience has shown that this method is quite stable and robust enough to be used in production systems.  Versions of this module have been in place at Brown for four years or more and have processed over 10,000 user requests during the last six months.  One of the common problems encountered when relying on screen scraping to provide functionality is that the HTML can change without notice.  In this case the ILLiad software is managed by the library so the chances of it changing without notice is small.  As an extra measure to protect against unforeseen HTML changes, we have place the HTML pages that are used with this module on a different web path than the user pages (something like http://illiad.school.edu/api-pages/) so that we can update the user pages without changing the markup that this module relies on.  </p>
<p>The module as implemented relies on the <a href="https://prometheus.atlas-sys.com/display/illiad/RemoteAuth+Authentication">RemoteAuth</a> in ILLiad.  This allows users to be authenticated via an HTTP header and can be used with systems like <a href="http://en.wikipedia.org/wiki/Shibboleth">Shibboleth</a> or <a href="http://en.wikipedia.org/wiki/Central_Authentication_Service">CAS</a>.  The module will pass the appropriate header for authentication and save the session cookie for further requests.  This eliminates the need to store the user's ILLiad credentials in a local database, which could be seen as a security risk.  If this is not a concern for your project, you could use a modified version of this module without enabling the RemoteAuth functionality.  Leave a comment below if you would like some help in getting started with that.  </p>
<h3 id="example-in-video">Example in video</h3>
<p>The screencast below shows an example of this module being integrated into the library's OpenURL resolver.  The user in this example authenticates with the campus Shibboleth system and places a request in ILLiad directly from the resolver interface.  There is no need to visit ILLiad to place the request.<br />
<div style="width: 700px; margin: 1em; padding:1em;">
<iframe src="http://www.screenr.com/embed/B1a8" width="650" height="396" frameborder="0"></iframe>
</div></p>
<p>If you are interested in learning more about this project or run into problems when getting started with the module, please leave a comment below.  </p>]]></content:encoded><description></description><guid>http://lawlesst.github.com/notebook/illiad-api.html</guid><pubDate>Mon, 31 Dec 2012 00:00:00 GMT</pubDate></item><item><title>Using Python and Pyjnius to connect to Jena models</title><link>http://lawlesst.github.com/notebook/pyjniusvivo.html</link><content:encoded><![CDATA[<p>At <a href="http://library.brown.edu/">work</a>, Im loading data into <a href="http://vivoweb.org/">Vivo</a>, an application built with the <a href="http://jena.apache.org/">Jena Framework</a>.  The Vivo web application comes with a nice set of bulk loading tools through an administrative interface.  However in the current Vivo release (1.5) there aren't web services or other tools for performing operations programatically on the underlying Jena models, without of course working directly with the Vivo codebase.  There is a separate <a href="https://github.com/vivo-project/VIVO-Harvester">harvester</a> project that has more utilities for getting data into the system.    </p>
<p>Here's a quick list of operations on the Vivo model that we would like to be able perform via ingestion scripts:</p>
<ul>
<li>generate a new, unique identifier to assign to new resources.  </li>
<li>find an existing resource in the model and return it's URI.  </li>
<li>load RDF created with processing scripts directly from those scripts. </li>
<li>delete RDF created with processing scripts.  </li>
</ul>
<p>A <a href="http://news.ycombinator.com/item?id=4407624">recent post</a> on Hacker News pointed me to a project called <a href="http://pyjnius.readthedocs.org/en/latest/index.html">Pyjnius</a>, which is "a Python library for accessing Java classes."  </p>
<p>For the last couple of weeks, we have been using Pyjnius - with pretty good results.  We are able to write our ingestion scripts in Python, using <a href="http://rdflib.readthedocs.org/en/latest/index.html">RDFLib</a>, but still use the Jena and Vivo harvester classes when needed to connect to the existing data.  (See steps below for installing Pyjnius).  </p>
<p>I have included a couple of examples of how you might use Pyjnius to connect to a Jena database (in our case Vivo).  This <a href="https://gist.github.com/3829194">Gist</a> contains code that we are using in Vivo data loading scripts.  We are just beginning to explore the <a href="https://github.com/vivo-project/VIVO-Harvester">Vivo harvester</a> in detail and hope to take fuller advantage of it moving forward.</p>
<p>If you are interested in Pyjnius + Jena or Vivo, leave a note and we can discuss other uses for this approach.  </p>
<h3 id="example-of-connecting-to-an-existing-jena-database">Example of connecting to an existing Jena database.</h3>
<pre><code class="python">from jnius import autoclass

#Load java classes
#Database setup
DBConnection = autoclass('com.hp.hpl.jena.db.DBConnection')
LayoutType = autoclass('com.hp.hpl.jena.sdb.store.LayoutType')
DatabaseType = autoclass('com.hp.hpl.jena.sdb.store.DatabaseType')
SDBConnection = autoclass('com.hp.hpl.jena.sdb.sql.SDBConnection')
SDBFactory = autoclass('com.hp.hpl.jena.sdb.SDBFactory')
StoreDesc = autoclass('com.hp.hpl.jena.sdb.StoreDesc')

storeDesc = StoreDesc(LayoutType.LayoutTripleNodesHash, DatabaseType.MySQL)
conn = SDBConnection(DB_URL, DB_USER, DB_PASSWD)
store = SDBFactory.connectStore(conn, storeDesc)
dataset = SDBFactory.connectDataset(store)
model = dataset.getNamedModel('http://vitro.mannlib.cornell.edu/default/vitro-kb-2')

namespaces = model.listNameSpaces()
while namespaces.hasNext():
    print namespaces.next()

model.close()
store.close()
conn.close()
</code></pre>

<p>The output for a default Vivo install should look something like the following:</p>
<pre><code>http://vitro.mannlib.cornell.edu/ns/vitro/public#
http://www.w3.org/1999/02/22-rdf-syntax-ns#
http://purl.org/NET/c4dm/event.owl#
http://purl.org/ontology/bibo/
http://xmlns.com/foaf/0.1/
http://www.w3.org/2002/07/owl#
http://purl.org/dc/terms/
http://vivoweb.org/ontology/core#
http://vitro.mannlib.cornell.edu/ns/vitro/0.7#
http://www.w3.org/2000/01/rdf-schema#
</code></pre>

<h4 id="performing-sparql-queries">Performing SPARQL queries</h4>
<p>This example is closer to the types of operations you might want to perform.  It executes a SPARQL select query on the Vivo model.  </p>
<pre><code class="python">from jnius import autoclass

QueryFactory = autoclass('com.hp.hpl.jena.query.QueryFactory')
QueryExecutionFactory = autoclass('com.hp.hpl.jena.query.QueryExecutionFactory')
ResultSetFormatter = autoclass('com.hp.hpl.jena.query.ResultSetFormatter')
String = autoclass('java.lang.String')

storeDesc = StoreDesc(LayoutType.LayoutTripleNodesHash, DatabaseType.MySQL)
conn = SDBConnection(DB_URL, DB_USER, DB_PASSWD)
store = SDBFactory.connectStore(conn, storeDesc)
dataset = SDBFactory.connectDataset(store)
model = dataset.getNamedModel('http://vitro.mannlib.cornell.edu/default/vitro-kb-2')

query = &quot;&quot;&quot;
PREFIX rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;
PREFIX rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt;
PREFIX owl:   &lt;http://www.w3.org/2002/07/owl#&gt;
SELECT ?thing ?label
WHERE
{
      ?thing rdf:type owl:Thing
      OPTIONAL { ?thing rdfs:label ?label } 
}
LIMIT 20
&quot;&quot;&quot;

query = QueryFactory.create(String(query))
qset = QueryExecutionFactory.create(query, model)
qexec = qset.execSelect()
results = ResultSetFormatter.toList(qexec).listIterator()

while True:
    if results.hasNext():
        next_result = results.next()
        uri = next_result.get('?thing').toString()
        label = next_result.get('?label').toString()
        print uri, label
    else:
        break

qset.close()
model.close()
store.close()
conn.close()
</code></pre>

<h4 id="pyjnius-installation">Pyjnius Installation</h4>
<p>The <a href="http://pyjnius.readthedocs.org/en/latest/installation.html">installation instructions</a> for Pyjnius are pretty straightforward.  I would recommend installing it with <a href="http://pypi.python.org/pypi/virtualenv">virtualenv</a>.  Below are the installation steps I took on an Ubuntu Server box but should be pretty similar on other platforms.  Make sure that you have a <a href="http://en.wikipedia.org/wiki/Java_Development_Kit">JDK</a> installed. You will also want to make sure your <a href="http://en.wikipedia.org/wiki/Classpath_(Java)">classpath</a> is set if you want to use external libraries.  </p>
<pre><code>vagrant@lucid32:~$ mkdir pyjnius-project
vagrant@lucid32:~$ cd pyjnius-project/
vagrant@lucid32:~/pyjnius-project$ virtualenv venv
New python executable in venv/bin/python
Installing setuptools............done.
Installing pip...............done.
(venv)vagrant@lucid32:~/pyjnius-project$ source venv/bin/activate
vagrant@lucid32:~/pyjnius-project$ pip install cython
Downloading/unpacking cython...
Successfully installed cython
Cleaning up...
(venv)vagrant@lucid32:~/pyjnius-project$ git clone git://github.com/kivy/pyjnius.git
Initialized empty Git repository in /home/vagrant/pyjnius-project/pyjnius/.git/
...
(venv)vagrant@lucid32:~/pyjnius-project$ cd pyjnius/
(venv)vagrant@lucid32:~/pyjnius-project/pyjnius$ python setup.py install
(venv)vagrant@lucid32:~/pyjnius-project/pyjnius$ cd ..
(venv)vagrant@lucid32:~/pyjnius-project/pyjnius$ python
Python 2.6.5 (r265:79063, Apr 16 2010, 13:09:56)
[GCC 4.4.3] on linux2
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; from jnius import autoclass
&gt;&gt;&gt; Stack = autoclass('java.util.Stack')
&gt;&gt;&gt; stack = Stack()
&gt;&gt;&gt; stack.push('hello')
'hello'
&gt;&gt;&gt; stack.push('world')
'world'
&gt;&gt;&gt; stack.pop()
'world'
&gt;&gt;&gt; stack.pop()
'hello'
&gt;&gt;&gt; exit()
</code></pre>]]></content:encoded><description></description><guid>http://lawlesst.github.com/notebook/pyjniusvivo.html</guid><pubDate>Wed, 03 Oct 2012 00:00:00 GMT</pubDate></item><item><title> Reading and writing RDF for VIVO with RDFAlchemy</title><link>http://lawlesst.github.com/notebook/vivo-rdfalchemy.html</link><content:encoded><![CDATA[<p>For the last few months I have been working on converting a diverse set of data about the university and faculty into RDF for import into <a href="http://www.vivoweb.org/">VIVO</a>, the semantic web application.  The workflow generally consists of mapping the incoming data to the VIVO ontology(s) and then writing a Python script to create the RDF necessary for loading into VIVO.  One of the tools I have come across and find effective is <a href="https://rdfalchemy.readthedocs.org/en/latest/">RDFAlchemy</a>.  RDFAlchemy takes its lead from the Python SQL toolkit <a href="http://www.sqlalchemy.org/">SQLAlchemy</a>. It allows for "a object type API access to an RDF Triplestore."  What this means in practice is that you can create a set of classes for reading and writing RDF for VIVO.  Once your classes are created they can be reused down the line for future RDF reading, writing, and SPARQL queries.  </p>
<p>To demonstrate, I have created a basic FacultyMember class definition that models RDF for loading information about faculty into VIVO.  For sample data I am using the <a href="http://iweb.dl.sourceforge.net/project/vivo/Data%20Ingest/people.csv">people.csv</a> file provided in the <a href="http://iweb.dl.sourceforge.net/project/vivo/Data%20Ingest/Data_Ingest_Guide.pdf">VIVO Data Ingest Guide</a>.<sup id="fnref:outdated"><a class="footnote-ref" href="#fn:outdated" rel="footnote">1</a></sup>  Each RDFAlchemy class definition has an RDF type assignment to identify the <a href="http://en.wikipedia.org/wiki/RDF_Schema#Classes">RDF Class</a> that they object is linked to.  The remaining attributes, known as descriptors, are the specific <a href="http://www.vivoweb.org/glossary/term/47">data or object properties</a> of the object.  The right hand side of the descriptor assignment includes whether the property is a single or repeating value (all single here) and the specific RDF property and namespace.  This will become the predicate in the outputted triples.  If you have worked with <a href="https://docs.djangoproject.com/en/dev/topics/db/models/">Django models</a> or SQLAlchemy previously, this should seem quite familiar.  </p>
<pre><code class="python">
class FacultyMember(rdfSubject):
    rdf_type = core.FacultyMember
    label = rdfSingle(RDFS.label)
    firstname = rdfSingle(foaf.firstName)
    middlename = rdfSingle(core.middleName)
    lastname = rdfSingle(foaf.lastName)
    work_email = rdfSingle(core.workEmail)
    phone = rdfSingle(core.workPhone)
    fax = rdfSingle(core.workFax)
    research_overview = rdfSingle(core.researchOverview)
    preferred_title = rdfSingle(core.preferredTitle)
    moniker = rdfSingle(vitro.moniker)
    people_id = rdfSingle(local.peopleID)

</code></pre>

<h3 id="writing-rdf">Writing RDF</h3>
<p>Now that the FacultyMember class is defined we can write RDF that we can load into VIVO.  The incoming data is in a CSV file and looks like this.   </p>
<pre><code class="csv">person_ID,name,first,last,middle,email,phone,fax,title
3130,&quot;Burks, Rosella &quot;,Rosella,Burks,,BurksR@univ.edu,963.555.1253,963.777.4065,Professor 
3297,&quot;Avila, Damien &quot;,Damien,Avila,,AvilaD@univ.edu,963.555.1352,963.777.7914,Professor 
</code></pre>

<p>Next we open and loop through the CSV file pulling out the values from cells and assigning them to our FaculyMember objects.   </p>
<pre><code class="python">
#Create a graph
g = rdfSubject.db

#Open the sample VIVO people file.
csv_url = 'http://iweb.dl.sourceforge.net/project/vivo/Data%20Ingest/people.csv'
people_file = urllib.urlopen(csv_url)
for count, row in enumerate(csv.DictReader(people_file)):
    #Create a URI for the person.
    person_uri = URIRef(&quot;%sfaculty%s&quot; % (app, count + 1))
    #Instantiate a FacultyMember object using the URI created above. 
    fac = FacultyMember(person_uri)
    fac.label = row.get('name').strip()
    fac.people_id = row.get('person_ID')
    fac.moniker = row.get('title')
    fac.firstname = row.get('first')
    middle_name = row.get('middle')
    if middle_name is not None and middle_name != &quot;&quot;:
        fac.middlename = row.get('middle')
    fac.lastname = row.get('last')
    fac.work_email = row.get('email')
    fac.phone = row.get('phone')
    fac.fax = row.get('fax')

print g.serialize(format='n3')
g.close()

</code></pre>

<p>The output of the script should look like the following.  This file could be loaded directly into VIVO using the "Add/remove RDF" tool from the administrative page.  </p>
<pre><code class="python">&lt;http://localhost/vivo/faculty8&gt; a core:FacultyMember;
    rdfs:label &quot;Derek, Antoine Mccoy&quot;;
    local:peopleID &quot;2561&quot;;
    vitro:moniker &quot;Curator&quot;;
    core:middleName &quot;Mccoy&quot;;
    core:workEmail &quot;DerekA@univ.edu&quot;;
    core:workFax &quot;963.777.5454&quot;;
    core:workPhone &quot;963.555.2992&quot;;
    foaf:firstName &quot;Antoine&quot;;
    foaf:lastName &quot;Derek&quot; .

&lt;http://localhost/vivo/faculty9&gt; a core:FacultyMember;
    rdfs:label &quot;Hawkins, Callie&quot;;
    local:peopleID &quot;1625&quot;;
    vitro:moniker &quot;Professor&quot;;
    core:workEmail &quot;HawkinsC@univ.edu&quot;;
    core:workFax &quot;963.777.4949&quot;;
    core:workPhone &quot;963.555.3350x6480&quot;;
    foaf:firstName &quot;Callie&quot;;
    foaf:lastName &quot;Hawkins&quot; .

</code></pre>

<h3 id="reading-rdf">Reading RDF</h3>
<p>The classes created for writing RDF with RDFAlchemy can also be helpful for extracting data from RDF.  For example, if you have exported a set of data from VIVO or retrieved it via a SPARQL query and now want to perform operations on it, the class definitions above will provide access to specific properties.  In the example below we load the <a href="http://iweb.dl.sourceforge.net/project/vivo/Data%20Ingest/people.n3">people.n3</a> file from the <a href="http://iweb.dl.sourceforge.net/project/vivo/Data%20Ingest/Data_Ingest_Guide.pdf">Data Ingest Guide</a> and filter it to show only those people who have the moniker "Assistant Professor".  The FacultyMember class, and all RDF Alchemy rdfSubject classes, has a method 'filter_by' which takes a descriptor and a value for querying.  </p>
<pre><code class="python">
#Load the n3 file as a rdfSubject db.
people_n3 = 'http://iweb.dl.sourceforge.net/project/vivo/Data%20Ingest/people.n3'
rdfSubject.db.load(people_n3, format='n3')
#Filter by all of the assistant professors in the graph.
asst_professors = FacultyMember.filter_by(moniker=&quot;Assistant Professor&quot;)
print '\n' + '=' * 20
print &quot;Assistant Professors&quot;
print '=' * 20 + '\n'
for fac in asst_professors:
    #Print full name, email, and url to vivo profile.
    print &quot;%s\t%s\t%s&quot; % (fac.label, fac.work_email, fac.resUri.toPython())
</code></pre>

<p>The output of this script should look like below.  </p>
<pre><code class="python">====================
Assistant Professors
====================

Quentin, Sam Hyde       QuentinS@univ.edu       http://localhost/vivo/faculty35
Mullins, Kimberly       MullinsK@univ.edu       http://localhost/vivo/faculty14
Chuck, Lloyd Haney      ChuckL@univ.edu http://localhost/vivo/faculty15

</code></pre>

<p>Another class method 'get_by' is also available for retrieving single class instances.    </p>
<pre><code class="python">#Use get_by to retrieve a single faculty member
faculty = FacultyMember.get_by(hr_id='3958')
print faculty.label
</code></pre>

<h3 id="wrap-up">Wrap Up</h3>
<p>The code below includes the snippets above and can be downloaded an run for testing.  RDFAlchemy is <a href="http://pypi.python.org/pypi/RDFAlchemy/">available on PyPi</a> and also on <a href="https://github.com/gjhiggins/RDFAlchemy">Github</a>.  There are <a href="https://github.com/gjhiggins/RDFAlchemy/tree/master/rdfalchemy/samples">other examples</a> in the Github repository that could be helpful for getting started.  </p>
<p>For the VIVO implementation work I am doing, I am building out RDFAlchemy class definitions for other VIVO classes, like InformationResources, Events, Roles, Positions, etc.  If you are interested in those, please leave a note below. </p>
<div style="width: 800px; margin: 1em; padding:1em; font-size:1em;">
<script src="https://gist.github.com/4429683.js"></script>
</div>

<div class="footnote">
<hr />
<ol>
<li id="fn:outdated">
<p>The Data Ingest Guide is written for the VIVO 1.1 release.  The ontology may have changed a bit so please verify before reusing this snippet.  I have retained the data properties from the guide for clarity.  &#160;<a class="footnote-backref" href="#fnref:outdated" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>]]></content:encoded><description></description><guid>http://lawlesst.github.com/notebook/vivo-rdfalchemy.html</guid><pubDate>Wed, 02 Jan 2013 00:00:00 GMT</pubDate></item></channel></rss>